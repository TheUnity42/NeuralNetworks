{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "\n",
    "from Attention import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "find_tokens = re.compile(r\"[\\w']+|[.,!?:;\\[\\]\\(\\)]\")\n",
    "\n",
    "def load_tokens(tokens_file):\n",
    "    \"\"\"\n",
    "        Load the pre-trained word embeddings from the embedding file\n",
    "        \"\"\"\n",
    "    # Load the word tokens\n",
    "    tokens = pd.read_csv(tokens_file, index_col=0)\n",
    "    tokens = tokens.index.values\n",
    "    tokens_dict = {}\n",
    "    tokens_dict['to_token'] = {token: i for i, token in enumerate(tokens)}\n",
    "    tokens_dict['to_word'] = {i: token for i, token in enumerate(tokens)}\n",
    "    return tokens_dict\n",
    "\n",
    "def sim_tokenize(text, tokens_dict):\n",
    "    \"\"\"\n",
    "        Tokenize the text and return the token indices\n",
    "        \"\"\"\n",
    "    # Tokenize the text\n",
    "    tokens = find_tokens.findall(text.lower())\n",
    "\n",
    "    # Get the token indices\n",
    "    tokens_indices = [tokens_dict['to_token'][token] for token in tokens]\n",
    "    tokens_indices.insert(0, tokens_dict['to_token']['<start>'])\n",
    "    tokens_indices.append(tokens_dict['to_token']['<end>'])\n",
    "    [tokens_indices.append(tokens_dict['to_token']['<pad>']) for i in range(10)]\n",
    "    return tokens_indices\n",
    "\n",
    "def detokenize(tokens_indices, tokens_dict):\n",
    "    \"\"\"\n",
    "        Convert the token indices to text\n",
    "        \"\"\"\n",
    "    # Detokenize the text\n",
    "    tokens = [tokens_dict['to_word'][i] for i in tokens_indices]\n",
    "    text = ' '.join(tokens).replace('<pad>', '')\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tok = load_tokens('tokens.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenized: [3, 11, 166, 12, 870, 4325, 5, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Rebuilt: <start> i am a test sentence . <end>          \n"
     ]
    }
   ],
   "source": [
    "tokenized = sim_tokenize('I am a test sentence.', tok)\n",
    "rebuilt = detokenize(tokenized, tok)\n",
    "print(f\"Tokenized: {tokenized}\")\n",
    "print(f\"Rebuilt: {rebuilt}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(128, 96, 128) (128, 8, 96, 96)\n"
     ]
    }
   ],
   "source": [
    "# q:  (128, 8, 96, 16) k:  (128, 8, 96, 16) v:  (128, 8, 96, 16)\n",
    "x = tf.random.uniform((128, 96, 128))\n",
    "\n",
    "mha = MultiHeadAttention(128, 8)\n",
    "\n",
    "output, attn = mha(x, x, x, None)\n",
    "print(output.shape, attn.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(128, 96, 128) (128, 8, 96, 96)\n"
     ]
    }
   ],
   "source": [
    "# q:  (128, 8, 96, 16) k:  (128, 8, 96, 16) v:  (128, 8, 96, 16)\n",
    "x = tf.random.uniform((128, 96, 128))\n",
    "\n",
    "mha = Fastformer_MultiHeadAttention(128, 8, 96)\n",
    "\n",
    "output = mha(x, x, x, None)\n",
    "print(output.shape, attn.shape)\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "fdcdff60b67b05b67ad0ae04d8e5c3b481a43b83a699826d48039a1889185218"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('tf-gpu': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
