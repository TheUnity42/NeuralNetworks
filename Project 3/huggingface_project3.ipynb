{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import numpy as np\n",
    "import tqdm\n",
    "import time\n",
    "\n",
    "from transformers import BertTokenizer, TFBertModel, TFGPT2Model, GPT2Tokenizer, TFGPT2LMHeadModel\n",
    "from Attention import AttentionUtils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFGPT2LMHeadModel.\n",
      "\n",
      "All the layers of TFGPT2LMHeadModel were initialized from the model checkpoint at gpt2.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFGPT2LMHeadModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"tfgp_t2lm_head_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "transformer (TFGPT2MainLayer multiple                  124439808 \n",
      "=================================================================\n",
      "Total params: 124,439,808\n",
      "Trainable params: 124,439,808\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "tokenizer.add_special_tokens({'pad_token': '<PAD>'})\n",
    "vocab_size = tokenizer.vocab_size\n",
    "\n",
    "gpt2 = TFGPT2LMHeadModel.from_pretrained('gpt2')\n",
    "gpt2.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(s, max_len=128):\n",
    "    tok = tokenizer.encode(bytes.decode(s.numpy()), max_length=max_len, padding='max_length')\n",
    "    return tf.constant(tok, dtype=tf.int32)\n",
    "\n",
    "\n",
    "def shift(x):\n",
    "    return x[:, :-1], x[:, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "492686\n",
      "the deep space nine transcripts - emissary emissary stardate: 46379.1 original airdate: 3 jan, 1993 on stardate 43997, captain jean-luc picard of the federation starship enterprise was kidnapped for six days by an invading force known as the borg.\n",
      " surgically altered, he was forced to lead an assault on starfleet at wolf 359.\n"
     ]
    }
   ],
   "source": [
    "sentences = tf.data.experimental.load(\n",
    "    'sentences_raw_gpttokens.tfrecord', compression='GZIP')\n",
    "print(len(sentences))\n",
    "for s in sentences.batch(2).take(1):\n",
    "    print(tokenizer.decode(s[0], skip_special_tokens=True))\n",
    "    print(tokenizer.decode(s[1], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratios = (0.8, 0.1, 0.1)\n",
    "assert sum(ratios) == 1\n",
    "\n",
    "BUFFER_SIZE = 10000\n",
    "BATCH_SIZE = 16\n",
    "\n",
    "sentences = tf.data.experimental.load(\n",
    "    'sentences_combined_gpttokens.tfrecord', compression='GZIP')\n",
    "sentences = sentences.shuffle(BUFFER_SIZE)\n",
    "cardinality = len(sentences)\n",
    "train_dataset = sentences.take(int(ratios[0] * cardinality))\n",
    "valid_dataset = sentences.skip(int(ratios[0] * cardinality)).take(int(ratios[1] * cardinality))\n",
    "test_dataset = sentences.skip(int(ratios[0] * cardinality) + int(ratios[1] * cardinality))\n",
    "\n",
    "# shuffle(BUFFER_SIZE, reshuffle_each_iteration=True)?\n",
    "\n",
    "train_dataset = train_dataset.batch(BATCH_SIZE).prefetch(tf.data.experimental.AUTOTUNE)\n",
    "valid_dataset = valid_dataset.batch(BATCH_SIZE).prefetch(tf.data.experimental.AUTOTUNE)\n",
    "test_dataset = test_dataset.batch(BATCH_SIZE).prefetch(tf.data.experimental.AUTOTUNE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42371 2119 265 265\n"
     ]
    }
   ],
   "source": [
    "print(len(sentences), len(train_dataset), len(valid_dataset), len(test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reorder(s):\n",
    "    return s[:,0,:], s[:,1,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HFModel(tf.keras.Model):\n",
    "    def __init__(self, model, vocab_size, dense, output_dense=True, make_base_trainable=False):\n",
    "        super(HFModel, self).__init__()\n",
    "        self.output_dense = output_dense\n",
    "        self.model = model\n",
    "        self.model.trainable = make_base_trainable\n",
    "        self.dense = tf.keras.layers.Dense(dense, activation='relu')\n",
    "        self.output_dense = tf.keras.layers.Dense(vocab_size, activation='softmax')\n",
    "\n",
    "    def call(self, inputs):\n",
    "        model_outs = self.model(inputs).last_hidden_state\n",
    "        # hidden_dense = self.dense(model_outs)        \n",
    "        outputs = self.output_dense(model_outs)\n",
    "        return outputs\n",
    "        # return tf.argmax(outputs, axis=-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFGPT2LMHeadModel.\n",
      "\n",
      "All the layers of TFGPT2LMHeadModel were initialized from the model checkpoint at gpt2.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFGPT2LMHeadModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "# model = HFModel(gpt2, vocab_size, 256, output_dense=False)\n",
    "model = TFGPT2LMHeadModel.from_pretrained(\n",
    "    \"gpt2\",\n",
    "    use_cache=False,\n",
    "    pad_token_id=tokenizer.pad_token_id,)\n",
    "\n",
    "checkpoint_path = \"./checkpoints/GPT2LM/train\"\n",
    "\n",
    "# ckpt = tf.train.Checkpoint(transformer=model,\n",
    "#                            optimizer=optimizer)\n",
    "\n",
    "# ckpt_manager = tf.train.CheckpointManager(ckpt, checkpoint_path, max_to_keep=3)\n",
    "\n",
    "model.compile(optimizer='adam', loss=tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "    from_logits=True), metrics=[tf.metrics.SparseCategoricalAccuracy()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "2119/2119 [==============================] - 681s 321ms/step - loss: nan - sparse_categorical_accuracy: 1.2746e-04\n",
      "\n",
      "Epoch 00001: saving model to ./checkpoints/GPT2LM\\train\n",
      "Epoch 2/3\n",
      "2119/2119 [==============================] - 667s 315ms/step - loss: nan - sparse_categorical_accuracy: 1.2331e-04\n",
      "\n",
      "Epoch 00002: saving model to ./checkpoints/GPT2LM\\train\n",
      "Epoch 3/3\n",
      "2119/2119 [==============================] - 652s 308ms/step - loss: nan - sparse_categorical_accuracy: 1.2561e-04\n",
      "\n",
      "Epoch 00003: saving model to ./checkpoints/GPT2LM\\train\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2884fded6a0>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_dataset.map(reorder), epochs=3, callbacks=[\n",
    "    tf.keras.callbacks.ModelCheckpoint(\n",
    "        filepath=checkpoint_path,\n",
    "        save_weights_only=True,\n",
    "        verbose=1)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input:\n",
      " )[shuttlepod] (tucker hears someone making gun noises. it's the boy, who is startled when trip activates an alarm.) tucker: what are you doing in my chair? q'ell: i didn't touch anything. i just like to look inside the ships that come here. tucker: you should have asked. q'ell: you might have said no. tucker: well, what do you think? q'ell: well, it's a little small and your thruster controls are hard to reach. tucker: maybe you need longer arms.\n",
      "Output:\n",
      " )[shuttlepod] (tucker hears someone making gun noises. it's the boy, who is startled when trip activates an alarm.) tucker: what are you doing in my chair? q'ell: i didn't touch anything. i just like to look inside the ships that come here. tucker: you should have asked. q'ell: you might have said no. tucker: well, what do you think? q'ell: well, it's a little small and your thruster controls are hard to reach. tucker: maybe you need longer arms.!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n"
     ]
    }
   ],
   "source": [
    "for s in test_dataset.take(1):\n",
    "    print(\"Input:\\n\", tokenizer.decode(s[0, 0, :], skip_special_tokens=True))\n",
    "    output = model.generate(s[0, 0, :][tf.newaxis, :], max_length=len(s[0,0,:])*2, temperature=0.7)\n",
    "    print(\"Output:\\n\", tokenizer.decode(output[0], skip_special_tokens=True))\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "fdcdff60b67b05b67ad0ae04d8e5c3b481a43b83a699826d48039a1889185218"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('tf-gpu': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
