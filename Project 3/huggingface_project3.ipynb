{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import numpy as np\n",
    "import tqdm\n",
    "import time\n",
    "\n",
    "from transformers import BertTokenizer, TFBertModel, TFGPT2Model, GPT2Tokenizer, TFGPT2LMHeadModel\n",
    "from Attention import AttentionUtils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFGPT2LMHeadModel.\n",
      "\n",
      "All the layers of TFGPT2LMHeadModel were initialized from the model checkpoint at gpt2.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFGPT2LMHeadModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"tfgp_t2lm_head_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "transformer (TFGPT2MainLayer multiple                  124439808 \n",
      "=================================================================\n",
      "Total params: 124,439,808\n",
      "Trainable params: 124,439,808\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "tokenizer.add_special_tokens({'pad_token': '<PAD>'})\n",
    "vocab_size = tokenizer.vocab_size\n",
    "\n",
    "gpt2 = TFGPT2LMHeadModel.from_pretrained('gpt2')\n",
    "# gpt2lm = TFGPT2LMHeadModel.from_pretrained('gpt2')\n",
    "# gpt2lm.summary()\n",
    "gpt2.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(s, max_len=128):\n",
    "    tok = tokenizer.encode(bytes.decode(s.numpy()), max_length=max_len, padding='max_length')\n",
    "    return tf.constant(tok, dtype=tf.int32)\n",
    "\n",
    "\n",
    "def shift(x):\n",
    "    return x[:, :-1], x[:, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "492686\n",
      "the deep space nine transcripts - emissary emissary stardate: 46379.1 original airdate: 3 jan, 1993 on stardate 43997, captain jean-luc picard of the federation starship enterprise was kidnapped for six days by an invading force known as the borg.\n",
      " surgically altered, he was forced to lead an assault on starfleet at wolf 359.\n"
     ]
    }
   ],
   "source": [
    "sentences = tf.data.experimental.load(\n",
    "    'sentences_raw_gpttokens.tfrecord', compression='GZIP')\n",
    "print(len(sentences))\n",
    "for s in sentences.batch(2).take(1):\n",
    "    print(tokenizer.decode(s[0], skip_special_tokens=True))\n",
    "    print(tokenizer.decode(s[1], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratios = (0.8, 0.1, 0.1)\n",
    "assert sum(ratios) == 1\n",
    "\n",
    "BUFFER_SIZE = 10000\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "sentences = tf.data.experimental.load(\n",
    "    'sentences_raw_gpttokens.tfrecord', compression='GZIP')\n",
    "sentences = sentences.take(100*BATCH_SIZE).batch(2).shuffle(BUFFER_SIZE)\n",
    "cardinality = len(sentences)\n",
    "train_dataset = sentences.take(int(ratios[0] * cardinality))\n",
    "valid_dataset = sentences.skip(int(ratios[0] * cardinality)).take(int(ratios[1] * cardinality))\n",
    "test_dataset = sentences.skip(int(ratios[0] * cardinality) + int(ratios[1] * cardinality))\n",
    "\n",
    "# shuffle(BUFFER_SIZE, reshuffle_each_iteration=True)?\n",
    "\n",
    "train_dataset = train_dataset.batch(BATCH_SIZE).prefetch(tf.data.experimental.AUTOTUNE)\n",
    "valid_dataset = valid_dataset.batch(BATCH_SIZE).prefetch(tf.data.experimental.AUTOTUNE)\n",
    "test_dataset = test_dataset.batch(BATCH_SIZE).prefetch(tf.data.experimental.AUTOTUNE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1600 40 5 5\n"
     ]
    }
   ],
   "source": [
    "print(len(sentences), len(train_dataset), len(valid_dataset), len(test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reorder(s):\n",
    "    return s[:,0,:], s[:,1,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(<tf.Tensor: shape=(32, 128), dtype=int32, numpy=\n",
      "array([[16106,    25,  1277, ..., 50257, 50257, 50257],\n",
      "       [  264,  1984,    78, ..., 50257, 50257, 50257],\n",
      "       [  288,   897,    11, ..., 50257, 50257, 50257],\n",
      "       ...,\n",
      "       [  264,  1984,    78, ..., 50257, 50257, 50257],\n",
      "       [ 3644,    25,  4686, ..., 50257, 50257, 50257],\n",
      "       [ 1976,   323,   430, ..., 50257, 50257, 50257]])>, <tf.Tensor: shape=(32, 128), dtype=int32, numpy=\n",
      "array([[  264,  1984,    78, ..., 50257, 50257, 50257],\n",
      "       [27334,   343,    25, ..., 50257, 50257, 50257],\n",
      "       [  288,   897,    25, ..., 50257, 50257, 50257],\n",
      "       ...,\n",
      "       [  267,  4598,    25, ..., 50257, 50257, 50257],\n",
      "       [  264,  1984,    78, ..., 50257, 50257, 50257],\n",
      "       [33217,  7143,   353, ..., 50257, 50257, 50257]])>)\n",
      "(<tf.Tensor: shape=(32, 128), dtype=int32, numpy=\n",
      "array([[  264,  1984,    78, ..., 50257, 50257, 50257],\n",
      "       [  969,    76,   461, ..., 50257, 50257, 50257],\n",
      "       [  783,    11,   922, ..., 50257, 50257, 50257],\n",
      "       ...,\n",
      "       [  288,  2724,   265, ..., 50257, 50257, 50257],\n",
      "       [  264,  1984,    78, ..., 50257, 50257, 50257],\n",
      "       [  288,   897,    25, ..., 50257, 50257, 50257]])>, <tf.Tensor: shape=(32, 128), dtype=int32, numpy=\n",
      "array([[  474,  1697,  7087, ..., 50257, 50257, 50257],\n",
      "       [  479,  8704,    25, ..., 50257, 50257, 50257],\n",
      "       [ 1312,  1101,   523, ..., 50257, 50257, 50257],\n",
      "       ...,\n",
      "       [  644, 23849, 13207, ..., 50257, 50257, 50257],\n",
      "       [  345,   290,  1312, ..., 50257, 50257, 50257],\n",
      "       [  479,  8704,    25, ..., 50257, 50257, 50257]])>)\n"
     ]
    }
   ],
   "source": [
    "for s in train_dataset.map(reorder).take(2):\n",
    "    print(s)\n",
    "    # ss = [t for t in s[0].numpy() if t != tokenizer.pad_token_id]\n",
    "    # ssp = [t for t in s[1].numpy() if t != tokenizer.pad_token_id]\n",
    "#     print(tokenizer.decode(s[0].numpy(), skip_special_tokens=True))\n",
    "#     print(tokenizer.decode(s[1].numpy(), skip_special_tokens=True))\n",
    "#     # greedy_out = gpt2lm.generate(tf.constant(ss)[tf.newaxis, :], max_length=len(ss)*2)\n",
    "#     greedy_out = gpt2lm(s[0])['logits']\n",
    "#     greedy_out = tf.argmax(greedy_out, axis=-1)\n",
    "#     # print(greedy_out)\n",
    "#     print(tokenizer.decode(greedy_out, skip_special_tokens=True))\n",
    "# #     break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HFModel(tf.keras.Model):\n",
    "    def __init__(self, model, vocab_size, dense, output_dense=True, make_base_trainable=False):\n",
    "        super(HFModel, self).__init__()\n",
    "        self.output_dense = output_dense\n",
    "        self.model = model\n",
    "        self.model.trainable = make_base_trainable\n",
    "        self.dense = tf.keras.layers.Dense(dense, activation='relu')\n",
    "        self.output_dense = tf.keras.layers.Dense(vocab_size, activation='softmax')\n",
    "\n",
    "    def call(self, inputs):\n",
    "        model_outs = self.model(inputs).last_hidden_state\n",
    "        # hidden_dense = self.dense(model_outs)        \n",
    "        outputs = self.output_dense(model_outs)\n",
    "        return outputs\n",
    "        # return tf.argmax(outputs, axis=-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = HFModel(gpt2, vocab_size, 256, output_dense=False)\n",
    "model = gpt2\n",
    "model.compile(optimizer='adam', loss=tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "    from_logits=True), metrics=[tf.metrics.SparseCategoricalAccuracy()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_14984/965095039.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['input_ids', 'attention_mask']"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.model_input_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[  618 47161 46078 ... 50257 50257 50257]\n",
      " [  477   584  2243 ... 50257 50257 50257]\n",
      " [ 4999    13 50257 ... 50257 50257 50257]\n",
      " ...\n",
      " [   58  2840    60 ... 50257 50257 50257]\n",
      " [  275  1518   272 ... 50257 50257 50257]\n",
      " [    8   264  1984 ... 50257 50257 50257]], shape=(32, 128), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[  264  1984    78 ... 50257 50257 50257]\n",
      " [ 3644    25  6509 ... 50257 50257 50257]\n",
      " [  264  1984    78 ... 50257 50257 50257]\n",
      " ...\n",
      " [  267  4598    25 ... 50257 50257 50257]\n",
      " [  479  8704    25 ... 50257 50257 50257]\n",
      " [  262  3173   389 ... 50257 50257 50257]], shape=(32, 128), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "for s in train_dataset.map(reorder).take(2):\n",
    "    print(s[0])\n",
    "    # print(model(s[0])['logits'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\jtalo\\.conda\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py:5043: calling gather (from tensorflow.python.ops.array_ops) with validate_indices is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "The `validate_indices` argument has no effect. Indices are always validated on CPU and never validated on GPU.\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": " required broadcastable shapes at loc(unknown)\n\t [[node Equal_1 (defined at \\.conda\\envs\\tf-gpu\\lib\\site-packages\\transformers\\modeling_tf_utils.py:884) ]] [Op:__inference_train_function_16818]\n\nFunction call stack:\ntrain_function\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_14984/638215851.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreorder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\.conda\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1181\u001b[0m                 _r=1):\n\u001b[0;32m   1182\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1183\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1184\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1185\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    887\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    891\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    922\u001b[0m       \u001b[1;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    923\u001b[0m       \u001b[1;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 924\u001b[1;33m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    925\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_created_variables\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    926\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
      "\u001b[1;32m~\\.conda\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3021\u001b[0m       (graph_function,\n\u001b[0;32m   3022\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m-> 3023\u001b[1;33m     return graph_function._call_flat(\n\u001b[0m\u001b[0;32m   3024\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0;32m   3025\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1958\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1959\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1960\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1961\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1962\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32m~\\.conda\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    589\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    590\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 591\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    592\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    593\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     57\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m:  required broadcastable shapes at loc(unknown)\n\t [[node Equal_1 (defined at \\.conda\\envs\\tf-gpu\\lib\\site-packages\\transformers\\modeling_tf_utils.py:884) ]] [Op:__inference_train_function_16818]\n\nFunction call stack:\ntrain_function\n"
     ]
    }
   ],
   "source": [
    "model.fit(train_dataset.map(reorder), epochs=1, steps_per_epoch=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[ 5170   257  2657 46091  2125   470  3177   881   286   257  4065\n",
      "   26760    13 50257 50257 50257 50257 50257 50257 50257 50257 50257\n",
      "   50257 50257 50257 50257 50257 50257 50257 50257 50257 50257 50257\n",
      "   50257 50257 50257 50257 50257 50257 50257 50257 50257 50257 50257\n",
      "   50257 50257 50257 50257 50257 50257 50257 50257 50257 50257 50257\n",
      "   50257 50257 50257 50257 50257 50257 50257 50257 50257 50257 50257\n",
      "   50257 50257 50257 50257 50257 50257 50257 50257 50257 50257 50257\n",
      "   50257 50257 50257 50257 50257 50257 50257 50257 50257 50257 50257\n",
      "   50257 50257 50257 50257 50257 50257 50257 50257 50257 50257 50257\n",
      "   50257 50257 50257 50257 50257 50257 50257 50257 50257 50257 50257\n",
      "   50257 50257 50257 50257 50257 50257 50257 50257 50257 50257 50257\n",
      "   50257 50257 50257 50257 50257 50257 50257]\n",
      "  [  264  1984    78    25  1595   470  2128   588   612   338   881\n",
      "     356   460   466   546   340    13 50257 50257 50257 50257 50257\n",
      "   50257 50257 50257 50257 50257 50257 50257 50257 50257 50257 50257\n",
      "   50257 50257 50257 50257 50257 50257 50257 50257 50257 50257 50257\n",
      "   50257 50257 50257 50257 50257 50257 50257 50257 50257 50257 50257\n",
      "   50257 50257 50257 50257 50257 50257 50257 50257 50257 50257 50257\n",
      "   50257 50257 50257 50257 50257 50257 50257 50257 50257 50257 50257\n",
      "   50257 50257 50257 50257 50257 50257 50257 50257 50257 50257 50257\n",
      "   50257 50257 50257 50257 50257 50257 50257 50257 50257 50257 50257\n",
      "   50257 50257 50257 50257 50257 50257 50257 50257 50257 50257 50257\n",
      "   50257 50257 50257 50257 50257 50257 50257 50257 50257 50257 50257\n",
      "   50257 50257 50257 50257 50257 50257 50257]]\n",
      "\n",
      " [[  267  4598    25   290   644   857   326  1612    30 50257 50257\n",
      "   50257 50257 50257 50257 50257 50257 50257 50257 50257 50257 50257\n",
      "   50257 50257 50257 50257 50257 50257 50257 50257 50257 50257 50257\n",
      "   50257 50257 50257 50257 50257 50257 50257 50257 50257 50257 50257\n",
      "   50257 50257 50257 50257 50257 50257 50257 50257 50257 50257 50257\n",
      "   50257 50257 50257 50257 50257 50257 50257 50257 50257 50257 50257\n",
      "   50257 50257 50257 50257 50257 50257 50257 50257 50257 50257 50257\n",
      "   50257 50257 50257 50257 50257 50257 50257 50257 50257 50257 50257\n",
      "   50257 50257 50257 50257 50257 50257 50257 50257 50257 50257 50257\n",
      "   50257 50257 50257 50257 50257 50257 50257 50257 50257 50257 50257\n",
      "   50257 50257 50257 50257 50257 50257 50257 50257 50257 50257 50257\n",
      "   50257 50257 50257 50257 50257 50257 50257]\n",
      "  [27334   343    25   340  1724   356   815   900   510   257 13401\n",
      "      12  2301   877   876  2214   284 22636   262 19824  2478    13\n",
      "   50257 50257 50257 50257 50257 50257 50257 50257 50257 50257 50257\n",
      "   50257 50257 50257 50257 50257 50257 50257 50257 50257 50257 50257\n",
      "   50257 50257 50257 50257 50257 50257 50257 50257 50257 50257 50257\n",
      "   50257 50257 50257 50257 50257 50257 50257 50257 50257 50257 50257\n",
      "   50257 50257 50257 50257 50257 50257 50257 50257 50257 50257 50257\n",
      "   50257 50257 50257 50257 50257 50257 50257 50257 50257 50257 50257\n",
      "   50257 50257 50257 50257 50257 50257 50257 50257 50257 50257 50257\n",
      "   50257 50257 50257 50257 50257 50257 50257 50257 50257 50257 50257\n",
      "   50257 50257 50257 50257 50257 50257 50257 50257 50257 50257 50257\n",
      "   50257 50257 50257 50257 50257 50257 50257]]\n",
      "\n",
      " [[   58 49257 15305    60 33896  3301    25   644   318   340    11\n",
      "     474   539    30 50257 50257 50257 50257 50257 50257 50257 50257\n",
      "   50257 50257 50257 50257 50257 50257 50257 50257 50257 50257 50257\n",
      "   50257 50257 50257 50257 50257 50257 50257 50257 50257 50257 50257\n",
      "   50257 50257 50257 50257 50257 50257 50257 50257 50257 50257 50257\n",
      "   50257 50257 50257 50257 50257 50257 50257 50257 50257 50257 50257\n",
      "   50257 50257 50257 50257 50257 50257 50257 50257 50257 50257 50257\n",
      "   50257 50257 50257 50257 50257 50257 50257 50257 50257 50257 50257\n",
      "   50257 50257 50257 50257 50257 50257 50257 50257 50257 50257 50257\n",
      "   50257 50257 50257 50257 50257 50257 50257 50257 50257 50257 50257\n",
      "   50257 50257 50257 50257 50257 50257 50257 50257 50257 50257 50257\n",
      "   50257 50257 50257 50257 50257 50257 50257]\n",
      "  [  474   539    25  4836 31402   618  1204    13 50257 50257 50257\n",
      "   50257 50257 50257 50257 50257 50257 50257 50257 50257 50257 50257\n",
      "   50257 50257 50257 50257 50257 50257 50257 50257 50257 50257 50257\n",
      "   50257 50257 50257 50257 50257 50257 50257 50257 50257 50257 50257\n",
      "   50257 50257 50257 50257 50257 50257 50257 50257 50257 50257 50257\n",
      "   50257 50257 50257 50257 50257 50257 50257 50257 50257 50257 50257\n",
      "   50257 50257 50257 50257 50257 50257 50257 50257 50257 50257 50257\n",
      "   50257 50257 50257 50257 50257 50257 50257 50257 50257 50257 50257\n",
      "   50257 50257 50257 50257 50257 50257 50257 50257 50257 50257 50257\n",
      "   50257 50257 50257 50257 50257 50257 50257 50257 50257 50257 50257\n",
      "   50257 50257 50257 50257 50257 50257 50257 50257 50257 50257 50257\n",
      "   50257 50257 50257 50257 50257 50257 50257]]], shape=(3, 2, 128), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# model.fit(train_dataset.batch(BATCH_SIZE).map(mask_last), epochs=3,\n",
    "#           validation_data=valid_dataset.batch(BATCH_SIZE).map(mask_last))\n",
    "\n",
    "for s in sentences.batch(3).take(1):\n",
    "    print(s)\n",
    "    # print(\"Output shape\", model(s[:,0,:])['logits'].shape)\n",
    "    # print(\"Label shape\", s[:,1,:].shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
    "train_accuracy = tf.keras.metrics.Mean(name='train_accuracy')\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "loss_function = AttentionUtils.mask_loss(tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "    from_logits=False, reduction='none'), tokenizer.pad_token_id)\n",
    "\n",
    "acc_function = AttentionUtils.get_masked_acc(tokenizer.pad_token_id)\n",
    "\n",
    "checkpoint_path = \"./checkpoints/GPT2LM/train\"\n",
    "\n",
    "ckpt = tf.train.Checkpoint(transformer=model,\n",
    "                           optimizer=optimizer)\n",
    "\n",
    "ckpt_manager = tf.train.CheckpointManager(ckpt, checkpoint_path, max_to_keep=3)\n",
    "\n",
    "# if a checkpoint exists, restore the latest checkpoint.\n",
    "# if ckpt_manager.latest_checkpoint:\n",
    "#   ckpt.restore(ckpt_manager.latest_checkpoint)\n",
    "#   print('Latest checkpoint restored!!')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_step_signature = [\n",
    "    tf.TensorSpec(shape=(None, None), dtype=tf.int32),\n",
    "    tf.TensorSpec(shape=(None, None), dtype=tf.int32),\n",
    "]\n",
    "\n",
    "@tf.function()\n",
    "def train_step(inp, tar):\n",
    "    with tf.GradientTape() as tape:\n",
    "\n",
    "        # print(\"Input shape\", inp.shape, tar.shape)\n",
    "\n",
    "        predictions = model(inp, training=True)['logits']\n",
    "        # predictions = tf.cast(predictions, tf.float32)\n",
    "        # print(\"Predictions type\", predictions.dtype, tar.dtype)\n",
    "        # print(\"Predictions shape\", predictions.shape, tar.shape)\n",
    "        loss = loss_function(tar, predictions)\n",
    "\n",
    "        gradients = tape.gradient(loss, model.trainable_variables)\n",
    "        optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "\n",
    "        train_loss(loss)\n",
    "        train_accuracy(acc_function(tar, predictions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EPOCH 1/1:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/40 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape (32, 128) (32, 128)\n",
      "WARNING:tensorflow:From C:\\Users\\jtalo\\.conda\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py:5043: calling gather (from tensorflow.python.ops.array_ops) with validate_indices is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "The `validate_indices` argument has no effect. Indices are always validated on CPU and never validated on GPU.\n",
      "Input shape (32, 128) (32, 128)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/40 [00:20<?, ?it/s]\n"
     ]
    },
    {
     "ename": "InternalError",
     "evalue": " 'cuModuleGetFunction(&function, module, kernel_name)' failed with 'CUDA_ERROR_INVALID_HANDLE'\n\t [[node sparse_categorical_crossentropy/clip_by_value (defined at c:\\Other Projects\\NeuralNetworks\\Project 3\\Attention.py:187) ]] [Op:__inference_train_step_20533]\n\nFunction call stack:\ntrain_step\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_15684/190899037.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m         \u001b[0minp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtar\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m         \u001b[0mtrain_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtar\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m         pbar.set_description(\n\u001b[0;32m     15\u001b[0m             f\"loss: {train_loss.result():.5f}, accuracy: {train_accuracy.result():.5f}\")\n",
      "\u001b[1;32m~\\.conda\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    887\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    891\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    948\u001b[0m         \u001b[1;31m# Lifting succeeded, so variables are initialized and we can run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    949\u001b[0m         \u001b[1;31m# stateless function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 950\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    951\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    952\u001b[0m       \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfiltered_flat_args\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3021\u001b[0m       (graph_function,\n\u001b[0;32m   3022\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m-> 3023\u001b[1;33m     return graph_function._call_flat(\n\u001b[0m\u001b[0;32m   3024\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0;32m   3025\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1958\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1959\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1960\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1961\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1962\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32m~\\.conda\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    589\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    590\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 591\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    592\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    593\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     57\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInternalError\u001b[0m:  'cuModuleGetFunction(&function, module, kernel_name)' failed with 'CUDA_ERROR_INVALID_HANDLE'\n\t [[node sparse_categorical_crossentropy/clip_by_value (defined at c:\\Other Projects\\NeuralNetworks\\Project 3\\Attention.py:187) ]] [Op:__inference_train_step_20533]\n\nFunction call stack:\ntrain_step\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 1\n",
    "for epoch in range(EPOCHS):\n",
    "    start = time.time()\n",
    "\n",
    "    train_loss.reset_states()\n",
    "    train_accuracy.reset_states()\n",
    "\n",
    "    print(f\"\\nEPOCH {epoch+1}/{EPOCHS}:\")\n",
    "    pbar = tqdm.tqdm(train_dataset)\n",
    "    for data in pbar:\n",
    "        inp, tar = data[:,0,:], data[:,1,:]\n",
    "\n",
    "        train_step(inp, tar)\n",
    "        pbar.set_description(\n",
    "            f\"loss: {train_loss.result():.5f}, accuracy: {train_accuracy.result():.5f}\")\n",
    "        ckpt_save_path = ckpt_manager.save()\n",
    "\n",
    "    print(f\"loss {train_loss.result()}\\t accuracy {train_accuracy.result()} in {np.round(time.time()-start, 2)} seconds\")\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "fdcdff60b67b05b67ad0ae04d8e5c3b481a43b83a699826d48039a1889185218"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('tf-gpu': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
