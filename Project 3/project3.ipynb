{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"all_scripts_raw.json\", \"r\")\n",
    "data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['DS9', 'TOS', 'TAS', 'TNG', 'VOY', 'ENT'])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DS9</th>\n",
       "      <th>TOS</th>\n",
       "      <th>TAS</th>\n",
       "      <th>TNG</th>\n",
       "      <th>VOY</th>\n",
       "      <th>ENT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>episode 0</th>\n",
       "      <td>\\n\\n\\n\\n\\n\\nThe Deep Space Nine Transcripts - ...</td>\n",
       "      <td>\\n\\n\\n\\n\\n\\nThe Star Trek Transcripts - The Ca...</td>\n",
       "      <td>\\n\\n\\n\\n\\n\\nThe Animated Star Trek Transcripts...</td>\n",
       "      <td>\\n\\n\\n\\n\\n\\nThe Next Generation Transcripts - ...</td>\n",
       "      <td>\\n\\n\\n\\n\\nThe Voyager Transcripts - Caretaker\\...</td>\n",
       "      <td>\\n\\n\\n\\n\\n\\nThe Enterprise Transcripts - Broke...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>episode 1</th>\n",
       "      <td>\\n\\n\\n\\n\\n\\nThe Deep Space Nine Transcripts - ...</td>\n",
       "      <td>\\n\\n\\n\\n\\n\\nThe Star Trek Transcripts - The Ma...</td>\n",
       "      <td>\\n\\n\\n\\n\\n\\nThe Animated Star Trek Transcripts...</td>\n",
       "      <td>\\n\\n\\n\\n\\n\\nThe Next Generation Transcripts - ...</td>\n",
       "      <td>\\n\\n\\n\\n\\n\\nThe Voyager Transcripts - Parallax...</td>\n",
       "      <td>\\n\\n\\n\\n\\n\\nThe Enterprise Transcripts - Fight...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>episode 2</th>\n",
       "      <td>\\n\\n\\n\\n\\n\\nThe Deep Space Nine Transcripts - ...</td>\n",
       "      <td>\\n\\n\\n\\n\\n\\nThe Star Trek Transcripts - Charli...</td>\n",
       "      <td>\\n\\n\\n\\n\\n\\nThe Animated Star Trek Transcripts...</td>\n",
       "      <td>\\n\\n\\n\\n\\n\\nThe Next Generation Transcripts - ...</td>\n",
       "      <td>\\n\\n\\n\\n\\n\\nThe Voyager Transcripts - Time and...</td>\n",
       "      <td>\\n\\n\\n\\n\\n\\nThe Enterprise Transcripts - Stran...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>episode 3</th>\n",
       "      <td>\\n\\n\\n\\n\\n\\nThe Deep Space Nine Transcripts - ...</td>\n",
       "      <td>\\n\\n\\n\\n\\n\\nThe Star Trek Transcripts - Where ...</td>\n",
       "      <td>\\n\\n\\n\\n\\n\\nThe Animated Star Trek Transcripts...</td>\n",
       "      <td>\\n\\n\\n\\n\\n\\nThe Next Generation Transcripts - ...</td>\n",
       "      <td>\\n\\n\\n\\n\\n\\n\\nThe Voyager Transcripts - Phage\\...</td>\n",
       "      <td>\\n\\n\\n\\n\\n\\nThe Enterprise Transcripts - Unexp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>episode 4</th>\n",
       "      <td>\\n\\n\\n\\n\\n\\nThe Deep Space Nine Transcripts - ...</td>\n",
       "      <td>\\n\\n\\n\\n\\n\\nThe Star Trek Transcripts - The Na...</td>\n",
       "      <td>\\n\\n\\n\\n\\n\\nThe Animated Star Trek Transcripts...</td>\n",
       "      <td>\\n\\n\\n\\n\\n\\nThe Next Generation Transcripts - ...</td>\n",
       "      <td>\\n\\n\\n\\n\\n\\nThe Voyager Transcripts - The Clou...</td>\n",
       "      <td>\\n\\n\\n\\n\\n\\nThe Enterprise Transcripts - Terra...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                         DS9  \\\n",
       "episode 0  \\n\\n\\n\\n\\n\\nThe Deep Space Nine Transcripts - ...   \n",
       "episode 1  \\n\\n\\n\\n\\n\\nThe Deep Space Nine Transcripts - ...   \n",
       "episode 2  \\n\\n\\n\\n\\n\\nThe Deep Space Nine Transcripts - ...   \n",
       "episode 3  \\n\\n\\n\\n\\n\\nThe Deep Space Nine Transcripts - ...   \n",
       "episode 4  \\n\\n\\n\\n\\n\\nThe Deep Space Nine Transcripts - ...   \n",
       "\n",
       "                                                         TOS  \\\n",
       "episode 0  \\n\\n\\n\\n\\n\\nThe Star Trek Transcripts - The Ca...   \n",
       "episode 1  \\n\\n\\n\\n\\n\\nThe Star Trek Transcripts - The Ma...   \n",
       "episode 2  \\n\\n\\n\\n\\n\\nThe Star Trek Transcripts - Charli...   \n",
       "episode 3  \\n\\n\\n\\n\\n\\nThe Star Trek Transcripts - Where ...   \n",
       "episode 4  \\n\\n\\n\\n\\n\\nThe Star Trek Transcripts - The Na...   \n",
       "\n",
       "                                                         TAS  \\\n",
       "episode 0  \\n\\n\\n\\n\\n\\nThe Animated Star Trek Transcripts...   \n",
       "episode 1  \\n\\n\\n\\n\\n\\nThe Animated Star Trek Transcripts...   \n",
       "episode 2  \\n\\n\\n\\n\\n\\nThe Animated Star Trek Transcripts...   \n",
       "episode 3  \\n\\n\\n\\n\\n\\nThe Animated Star Trek Transcripts...   \n",
       "episode 4  \\n\\n\\n\\n\\n\\nThe Animated Star Trek Transcripts...   \n",
       "\n",
       "                                                         TNG  \\\n",
       "episode 0  \\n\\n\\n\\n\\n\\nThe Next Generation Transcripts - ...   \n",
       "episode 1  \\n\\n\\n\\n\\n\\nThe Next Generation Transcripts - ...   \n",
       "episode 2  \\n\\n\\n\\n\\n\\nThe Next Generation Transcripts - ...   \n",
       "episode 3  \\n\\n\\n\\n\\n\\nThe Next Generation Transcripts - ...   \n",
       "episode 4  \\n\\n\\n\\n\\n\\nThe Next Generation Transcripts - ...   \n",
       "\n",
       "                                                         VOY  \\\n",
       "episode 0  \\n\\n\\n\\n\\nThe Voyager Transcripts - Caretaker\\...   \n",
       "episode 1  \\n\\n\\n\\n\\n\\nThe Voyager Transcripts - Parallax...   \n",
       "episode 2  \\n\\n\\n\\n\\n\\nThe Voyager Transcripts - Time and...   \n",
       "episode 3  \\n\\n\\n\\n\\n\\n\\nThe Voyager Transcripts - Phage\\...   \n",
       "episode 4  \\n\\n\\n\\n\\n\\nThe Voyager Transcripts - The Clou...   \n",
       "\n",
       "                                                         ENT  \n",
       "episode 0  \\n\\n\\n\\n\\n\\nThe Enterprise Transcripts - Broke...  \n",
       "episode 1  \\n\\n\\n\\n\\n\\nThe Enterprise Transcripts - Fight...  \n",
       "episode 2  \\n\\n\\n\\n\\n\\nThe Enterprise Transcripts - Stran...  \n",
       "episode 3  \\n\\n\\n\\n\\n\\nThe Enterprise Transcripts - Unexp...  \n",
       "episode 4  \\n\\n\\n\\n\\n\\nThe Enterprise Transcripts - Terra...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(data.keys())\n",
    "df = pd.DataFrame(data)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for series in df:\n",
    "    for ep in df[series].index:\n",
    "        if type(df[series][ep]) == str:\n",
    "            df[series][ep] = re.sub(r'\\s+', ' ', df[series][ep].strip())\n",
    "\n",
    "# df['DS9'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scenes = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['This is a regex test ',\n",
       " '[bracket] other text ',\n",
       " '[Ops] is here ',\n",
       " '[test] more text [OC] this is comms [on screen] yo']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = \"This is a regex test [bracket] other text [Ops] is here [test] more text [OC] this is comms [on screen] yo\"\n",
    "scene_regex = re.compile(r'(?=[\\[]+(?!OC)+(?!on))')\n",
    "scene_regex.split(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for series in df_scenes:\n",
    "    for ep in df_scenes[series].index:\n",
    "        if type(df[series][ep]) == str:\n",
    "            df_scenes[series][ep] = scene_regex.split(df_scenes[series][ep])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The Deep Space Nine Transcripts - Past Prologue Past Prologue Stardate: Unknown Original Airdate: 11 Jan, 1993 ',\n",
       " \"[Replimat] GARAK: It's Doctor Bashir, isn't it? Of course it is. May I introduce myself? BASHIR: Er, yes, yes, of course. GARAK: My name is Garak. Cardassian by birth, obviously. The only one of us left on this station, as a matter of fact, so I do appreciate making new friends whenever I can. You are new to this station, I believe. BASHIR: I am, yes. Though, though I understand you've been here quite a while. GARAK: Ah, you know of me then. BASHIR: Would you care for some of this Tarkalean tea? It's very good. GARAK: What a thoughtful young man. How nice that we've met. BASHIR: You know, some people say that you remained on DS Nine as the eyes and ears of your fellow Cardassians. GARAK: You don't say? Doctor, you're not intimating that I'm considered some sort of spy, are you? BASHIR: I wouldn't know, sir. GARAK: Ah. An open mind. The essence of intellect. As you may also know, I have a clothing shop nearby, so if you should require any apparel, or merely wish, as I do, for a bit of enjoyable company now and then, I'm at your disposal, Doctor. BASHIR: You're very kind, Mister Garak. GARAK: Oh, it's just Garak. Plain, simple Garak. Now, good day to you, Doctor. I'm so glad to have made such an interesting new friend today. \",\n",
       " \"[Ops] BASHIR: You won't never believe who just sat down next to me at the Replimat O'BRIEN: Major, upper pylon three'll be shut down for maintenance for forty-eight hours. BASHIR: The spy! Garak, the Cardassian. SISKO: We don't know for a fact Garak's a spy, Doctor. BASHIR: He is. You should have heard him. He introduced himself and he struck up conversation just like that. he was making contact with me, with me of all people. DAX: What do you think he might want from you, Julian? BASHIR: I don't know. Federation medical secrets? Rest assured they're safe with me, Commander. SISKO: I'm sure they are, Doctor Bashir. BASHIR: In fact, Chief O'Brien, I think you should place a monitoring device on me. Well, just in case he's up to something? SISKO: I don't think that'll be necessary, Doctor. Just be very cautious when you're around him. KIRA: (who's had a hair cut) Commander? We've got a small craft taking evasive action. Cardassian war vessel in pursuit. SISKO: On screen. KIRA: That's Bajoran. That damned Cardassian's firing at a Bajoran scout ship in Bajoran space! SISKO: Mister O'Brien? O'BRIEN: Confirmed, sir. They've crossed into Bajoran space. SISKO: Open a hailing frequency to the Cardassians. O'BRIEN: Channel open. SISKO: Cardassian vessel, you are violating Bajoran space. Break off your pursuit. Repeat, break off now. O'BRIEN: No reply from the Cardassians. The Bajoran vessel is hailing us. SISKO: Open the channel. TAHNA [OC]: Space station, do you read? Space station O'BRIEN: We can only get audio, Commander. SISKO: This is Benjamin Sisko, Starfleet Commander of the station. Who are you? Why are they pursuing? TAHNA [OC]: Please! Repeating request for emergency docking! Please! DAX: The Bajoran scout ship is badly damaged. Structural integrity is failing. (The little ship gets hit again) DAX: He's breaking up. SISKO: Get him out, Mister O'Brien. O'BRIEN: Aye, sir. (KaBOOM, and a crouching figure is beamed in) BASHIR: Medical assistance to Ops. TAHNA: My name is Tahna Los. Request political asylum. Kira? (after the opening credits, medics are wheeling Tahna away) KIRA: His name is Tahna Los. We fought together in the underground. O'BRIEN: Commander, the Cardassians are hailing us. KIRA: Now they want to talk. O'BRIEN: They're hopping mad. SISKO: Open the channel, Mister O'Brien. GUL DANAR [on viewscreen]: Federation Commander, you've taken aboard a known criminal. You will turn him over to us. SISKO: He has requested asylum. GUL DANAR [on viewscreen]: You have not granted it. SISKO: To be honest, I haven't decided yet. GUL DANAR [on viewscreen]: He is Kohn-Ma! Even the Bajorans would not grant his kind asylum. He has committed heinous crimes against the Cardassian people and I demand you release him to our custody. SISKO: I'll investigate the matter immediately. In the interim, if you'd care to dock your vessel, I'll be glad to hear an explanation for having violated Bajoran space and threatened a Federation facility. GUL DANAR [on viewscreen]: We have made no threat to your facility. SISKO: I stand corrected. Sisko out. (transmission ends) SISKO: The Major and I will be at the Infirmary. I'd like some time to talk with this fellow Tahna. When Gul Danar comes in, it'd be nice if we had a few docking regulations to keep him outside a while. O'BRIEN: Understood. (Sisko and Kira get onto the lift) KIRA: You're not seriously considering handing Tahna over to the Cardassians? \"]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_scenes['DS9'][1][:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Vocab:\n",
    "    def __init__(self):\n",
    "        self.words = []\n",
    "        self.word_count = []\n",
    "        self.df = pd.DataFrame(columns=['word', 'count'])\n",
    "\n",
    "    def add_word(self, word):\n",
    "        if word in self.words:\n",
    "            self.word_count[self.words.index(word)] += 1\n",
    "        else:\n",
    "            self.words.append(word)\n",
    "            self.word_count.append(1)\n",
    "\n",
    "    def get_word_count(self, word):\n",
    "        if word in self.words:\n",
    "            return self.word_count[self.words.index(word)]\n",
    "        else:\n",
    "            return 0\n",
    "\n",
    "    def rebuild_dataframe(self):\n",
    "        self.df = pd.DataFrame({\"word\": vocab.words, \"count\": vocab.word_count})\n",
    "        # for i in range(len(self.words)):\n",
    "        #     self.df.loc[i] = [self.words[i], self.word_count[i]]\n",
    "        self.df.sort_values('count', ascending=False, inplace=True)\n",
    "\n",
    "    def get_as_dataframe(self):\n",
    "        return self.df\n",
    "\n",
    "    def get_total_size(self):\n",
    "        return sum(self.word_count)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.words)\n",
    "\n",
    "    def get_words(self, sorted=True):\n",
    "        # if sorted:\n",
    "        #     return self.words.sort_values('count', ascending=False)\n",
    "        # else:\n",
    "        return self.words\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_words = re.compile(r'[\\s\\[\\]\\(\\),.?!:]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading words...\n",
      "Finished loading DS9\n",
      "Finished loading TOS\n",
      "Finished loading TAS\n",
      "Finished loading TNG\n",
      "Finished loading VOY\n",
      "Finished loading ENT\n",
      "Unique words: 58581\n",
      "Generating Dataframe...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "vocab = Vocab()\n",
    "\n",
    "print(\"Loading words...\")\n",
    "\n",
    "for series in df:\n",
    "    for ep in df[series]:\n",
    "        if type(ep) != str:\n",
    "            continue\n",
    "        word_split = re.split(r'[\\s\\[\\]\\(\\),.?!:]', ep.strip())\n",
    "        words = [w.strip() for w in word_split if w != '' and not w.isdigit()]\n",
    "        nums = [w for w in word_split if w.isdigit()]\n",
    "        digits = []\n",
    "        for n in nums:\n",
    "            l = re.split(r'(\\d)', n)\n",
    "            for d in l:\n",
    "                if d.isdigit():\n",
    "                    digits.append(d)\n",
    "\n",
    "        for w in words:\n",
    "            vocab.add_word(w)\n",
    "\n",
    "        for w in digits:\n",
    "            vocab.add_word(w)\n",
    "    print(f\"Finished loading {series}\")\n",
    "\n",
    "print(\"Unique words:\", len(vocab))\n",
    "print(\"Generating Dataframe...\")\n",
    "vocab.rebuild_dataframe()\n",
    "vocab.get_as_dataframe().to_csv('all_vocab.csv')\n",
    "print(\"Done!\")\n",
    "\n",
    "# vocab.get_as_dataframe().head()\n",
    "# re.split(r'[\\s\\[\\]\\(\\),.?!:]+', df_scenes['DS9'][1][1].strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(vocab.words), len(vocab.word_count)\n",
    "voc_df = pd.DataFrame({\"words\": vocab.words, \"counts\": vocab.word_count})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "voc_df.sort_values('counts', ascending=False, inplace=True)\n",
    "voc_df.head()\n",
    "voc_df.to_csv(\"vocab.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37182\n"
     ]
    }
   ],
   "source": [
    "vl = len(voc_df[voc_df['counts'] > 1])\n",
    "voc_df_u = voc_df[voc_df['counts'] > 1]\n",
    "voc_df_u.reset_index(inplace=True)\n",
    "print(vl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout, Activation\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.utils import Sequence\n",
    "tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(word, vocab_df):\n",
    "    if word in vocab_df['words'].to_list():\n",
    "        idx = vocab_df[vocab_df['words'] == word].index[0]\n",
    "        arr = np.zeros(len(vocab_df))\n",
    "        arr[idx] = 1.\n",
    "        return arr\n",
    "    else:\n",
    "        return np.zeros(len(vocab_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WordFromVocab(Sequence):\n",
    "    def __init__(self, vocab_df, batch_size):\n",
    "        self.vocab_df = vocab_df\n",
    "        self.batch_size = batch_size\n",
    "        self.indices = np.arange(len(vocab_df))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.vocab_df) // self.batch_size\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        start = idx * self.batch_size\n",
    "        end = (idx + 1) * self.batch_size\n",
    "        arr = np.array([tokenize(w, self.vocab_df) for w in self.vocab_df['words'][start:end]], dtype=np.float32)\n",
    "        \n",
    "        return arr, arr\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        np.random.shuffle(self.indices)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "fdcdff60b67b05b67ad0ae04d8e5c3b481a43b83a699826d48039a1889185218"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('tf-gpu': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
